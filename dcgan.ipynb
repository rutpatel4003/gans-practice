{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 2e-4\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = 64\n",
    "CHANNELS_IMG = 1\n",
    "Z_DIM = 100\n",
    "NUM_EPOCHS = 10\n",
    "FEATURES_DISC = 64\n",
    "FEATURES_GEN = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels_img, features_d):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Conv2d(channels_img, features_d, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            self._block(features_d, features_d*2, 4, 2, 1), \n",
    "            self._block(features_d*2, features_d*4, 4, 2, 1),\n",
    "            self._block(features_d*4, features_d*8, 4, 2, 1),\n",
    "            nn.Conv2d(features_d*8, 1, kernel_size=4, stride=2, padding=0),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.disc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, channels_img, featuresd_d):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            self._block(z_dim, featuresd_d*16, 4, 1, 0),\n",
    "            self._block(featuresd_d*16, featuresd_d*8, 4, 2, 1),\n",
    "            self._block(featuresd_d*8, featuresd_d*4, 4, 2, 1),\n",
    "            self._block(featuresd_d*4, featuresd_d*2, 4, 2, 1),\n",
    "            nn.ConvTranspose2d(featuresd_d*2, channels_img, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    N, in_channels, H, W = 8, 3, 64, 64\n",
    "    z_dim = 100\n",
    "    x = torch.randn((N, in_channels, H, W))\n",
    "    disc = Discriminator(in_channels, 8)\n",
    "    initialize_weights(disc)\n",
    "    assert disc(x).shape == (N, 1, 1, 1)\n",
    "    gen = Generator(z_dim, in_channels, 8)\n",
    "    initialize_weights(gen)\n",
    "    z = torch.randn((N, z_dim, 1, 1))\n",
    "    assert gen(z).shape == (N, in_channels, H, W)\n",
    "    print('SUCCESS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = v2.Compose([\n",
    "    v2.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float, scale=True),\n",
    "    v2.Normalize([0.5 for _ in range(CHANNELS_IMG)], [0.5 for _ in range(CHANNELS_IMG)]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST(root='MNIST/', train=True, transform=transforms, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "gen = Generator(Z_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\n",
    "disc = Discriminator(CHANNELS_IMG, FEATURES_DISC).to(device)\n",
    "initialize_weights(gen)\n",
    "initialize_weights(disc)\n",
    "\n",
    "opt_gen = torch.optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "opt_disc = torch.optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(32, Z_DIM, 1, 1).to(device)\n",
    "writer_real = SummaryWriter(f\"logs/real\")\n",
    "writer_fake = SummaryWriter(f\"logs/fake\")\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75f3bcb3e9d4f36a266b731171a4f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/938 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10] Batch 0/938                   Loss D: 0.1480, loss G: 2.7666\n",
      "Epoch [0/10] Batch 100/938                   Loss D: 0.0637, loss G: 3.2047\n",
      "Epoch [0/10] Batch 200/938                   Loss D: 0.0334, loss G: 4.7036\n",
      "Epoch [0/10] Batch 300/938                   Loss D: 0.0514, loss G: 3.9083\n",
      "Epoch [0/10] Batch 400/938                   Loss D: 0.3200, loss G: 2.4468\n",
      "Epoch [0/10] Batch 500/938                   Loss D: 0.0738, loss G: 3.7355\n",
      "Epoch [0/10] Batch 600/938                   Loss D: 0.0386, loss G: 4.4156\n",
      "Epoch [0/10] Batch 700/938                   Loss D: 0.2284, loss G: 1.6513\n",
      "Epoch [0/10] Batch 800/938                   Loss D: 0.2810, loss G: 1.3732\n",
      "Epoch [0/10] Batch 900/938                   Loss D: 0.4051, loss G: 3.4780\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515a9d2ca3314c22a3c4dcd57f535919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/938 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Batch 0/938                   Loss D: 0.0797, loss G: 2.9424\n",
      "Epoch [1/10] Batch 100/938                   Loss D: 0.1650, loss G: 2.5974\n",
      "Epoch [1/10] Batch 200/938                   Loss D: 0.0654, loss G: 3.9928\n",
      "Epoch [1/10] Batch 300/938                   Loss D: 0.0580, loss G: 4.0905\n",
      "Epoch [1/10] Batch 400/938                   Loss D: 0.0537, loss G: 4.0543\n",
      "Epoch [1/10] Batch 500/938                   Loss D: 0.0529, loss G: 3.1256\n",
      "Epoch [1/10] Batch 600/938                   Loss D: 0.1106, loss G: 2.7881\n",
      "Epoch [1/10] Batch 700/938                   Loss D: 0.0403, loss G: 3.7445\n",
      "Epoch [1/10] Batch 800/938                   Loss D: 0.0318, loss G: 3.7384\n",
      "Epoch [1/10] Batch 900/938                   Loss D: 0.1970, loss G: 4.1271\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22ca77d6503489e9e2ad024f0a45a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/938 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Batch 0/938                   Loss D: 0.0537, loss G: 4.4720\n",
      "Epoch [2/10] Batch 100/938                   Loss D: 0.0228, loss G: 4.7947\n",
      "Epoch [2/10] Batch 200/938                   Loss D: 0.6211, loss G: 4.1834\n",
      "Epoch [2/10] Batch 300/938                   Loss D: 0.0635, loss G: 3.4289\n",
      "Epoch [2/10] Batch 400/938                   Loss D: 0.0493, loss G: 4.4751\n",
      "Epoch [2/10] Batch 500/938                   Loss D: 0.0215, loss G: 4.8764\n",
      "Epoch [2/10] Batch 600/938                   Loss D: 0.0880, loss G: 3.6685\n",
      "Epoch [2/10] Batch 700/938                   Loss D: 0.0566, loss G: 3.8856\n",
      "Epoch [2/10] Batch 800/938                   Loss D: 0.0768, loss G: 3.4655\n",
      "Epoch [2/10] Batch 900/938                   Loss D: 0.0429, loss G: 5.5308\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86fe2e7960194d6092a26b32028d7ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/938 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10] Batch 0/938                   Loss D: 0.0207, loss G: 4.8198\n",
      "Epoch [3/10] Batch 100/938                   Loss D: 0.3560, loss G: 2.0467\n",
      "Epoch [3/10] Batch 200/938                   Loss D: 0.3107, loss G: 2.6734\n",
      "Epoch [3/10] Batch 300/938                   Loss D: 0.0451, loss G: 4.2749\n",
      "Epoch [3/10] Batch 400/938                   Loss D: 0.0156, loss G: 4.9387\n",
      "Epoch [3/10] Batch 500/938                   Loss D: 0.0184, loss G: 4.9710\n",
      "Epoch [3/10] Batch 600/938                   Loss D: 0.0506, loss G: 3.1264\n",
      "Epoch [3/10] Batch 700/938                   Loss D: 0.4508, loss G: 0.1944\n",
      "Epoch [3/10] Batch 800/938                   Loss D: 0.0615, loss G: 3.9810\n",
      "Epoch [3/10] Batch 900/938                   Loss D: 0.0767, loss G: 2.8835\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b2292898e9444aa90c6dd476c25297e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/938 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10] Batch 0/938                   Loss D: 0.1522, loss G: 5.1512\n",
      "Epoch [4/10] Batch 100/938                   Loss D: 0.1053, loss G: 3.2524\n",
      "Epoch [4/10] Batch 200/938                   Loss D: 0.0171, loss G: 4.3776\n",
      "Epoch [4/10] Batch 300/938                   Loss D: 0.0186, loss G: 4.9874\n",
      "Epoch [4/10] Batch 400/938                   Loss D: 2.3290, loss G: 0.0031\n",
      "Epoch [4/10] Batch 500/938                   Loss D: 0.1487, loss G: 3.8655\n",
      "Epoch [4/10] Batch 600/938                   Loss D: 0.1184, loss G: 4.1417\n",
      "Epoch [4/10] Batch 700/938                   Loss D: 0.0444, loss G: 3.4296\n",
      "Epoch [4/10] Batch 800/938                   Loss D: 0.0658, loss G: 2.6574\n",
      "Epoch [4/10] Batch 900/938                   Loss D: 0.0652, loss G: 3.5857\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76266bbff0ce4ec79d0dacb10e3e117f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/938 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10] Batch 0/938                   Loss D: 0.0281, loss G: 4.9689\n",
      "Epoch [5/10] Batch 100/938                   Loss D: 0.0487, loss G: 3.2039\n",
      "Epoch [5/10] Batch 200/938                   Loss D: 0.2898, loss G: 8.2339\n",
      "Epoch [5/10] Batch 300/938                   Loss D: 0.0178, loss G: 4.9057\n",
      "Epoch [5/10] Batch 400/938                   Loss D: 0.0135, loss G: 5.0036\n",
      "Epoch [5/10] Batch 500/938                   Loss D: 0.0539, loss G: 3.9341\n",
      "Epoch [5/10] Batch 600/938                   Loss D: 0.2190, loss G: 1.5815\n",
      "Epoch [5/10] Batch 700/938                   Loss D: 0.0234, loss G: 4.2869\n",
      "Epoch [5/10] Batch 800/938                   Loss D: 0.0816, loss G: 3.6089\n",
      "Epoch [5/10] Batch 900/938                   Loss D: 0.7370, loss G: 0.5250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2873050e63431bb7574cc4125a22b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/938 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10] Batch 0/938                   Loss D: 1.6781, loss G: 11.5139\n",
      "Epoch [6/10] Batch 100/938                   Loss D: 0.2243, loss G: 2.9681\n",
      "Epoch [6/10] Batch 200/938                   Loss D: 0.0560, loss G: 2.9741\n",
      "Epoch [6/10] Batch 300/938                   Loss D: 0.0182, loss G: 5.0267\n",
      "Epoch [6/10] Batch 400/938                   Loss D: 0.0083, loss G: 5.3834\n",
      "Epoch [6/10] Batch 500/938                   Loss D: 0.0128, loss G: 5.0845\n",
      "Epoch [6/10] Batch 600/938                   Loss D: 0.0042, loss G: 6.0180\n",
      "Epoch [6/10] Batch 700/938                   Loss D: 0.0156, loss G: 4.4391\n",
      "Epoch [6/10] Batch 800/938                   Loss D: 1.0289, loss G: 0.5668\n",
      "Epoch [6/10] Batch 900/938                   Loss D: 0.3478, loss G: 3.9201\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d90c6dddfd564106b242d51fd213734f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8:   0%|          | 0/938 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10] Batch 0/938                   Loss D: 0.0736, loss G: 4.2469\n",
      "Epoch [7/10] Batch 100/938                   Loss D: 0.0368, loss G: 3.6451\n",
      "Epoch [7/10] Batch 200/938                   Loss D: 0.0971, loss G: 2.6093\n",
      "Epoch [7/10] Batch 300/938                   Loss D: 0.2285, loss G: 2.9570\n",
      "Epoch [7/10] Batch 400/938                   Loss D: 0.0205, loss G: 4.6874\n",
      "Epoch [7/10] Batch 500/938                   Loss D: 0.3762, loss G: 1.5155\n",
      "Epoch [7/10] Batch 600/938                   Loss D: 0.1435, loss G: 3.3669\n",
      "Epoch [7/10] Batch 700/938                   Loss D: 0.0272, loss G: 4.3319\n",
      "Epoch [7/10] Batch 800/938                   Loss D: 0.0201, loss G: 4.7503\n",
      "Epoch [7/10] Batch 900/938                   Loss D: 0.4434, loss G: 2.2299\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d337a54aeb414ba138be5be68706f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9:   0%|          | 0/938 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10] Batch 0/938                   Loss D: 0.0538, loss G: 4.1865\n",
      "Epoch [8/10] Batch 100/938                   Loss D: 0.0873, loss G: 3.6998\n",
      "Epoch [8/10] Batch 200/938                   Loss D: 0.1317, loss G: 4.4159\n",
      "Epoch [8/10] Batch 300/938                   Loss D: 0.0447, loss G: 4.3590\n",
      "Epoch [8/10] Batch 400/938                   Loss D: 0.0127, loss G: 4.7101\n",
      "Epoch [8/10] Batch 500/938                   Loss D: 0.1452, loss G: 3.4864\n",
      "Epoch [8/10] Batch 600/938                   Loss D: 0.2896, loss G: 2.8867\n",
      "Epoch [8/10] Batch 700/938                   Loss D: 0.1116, loss G: 2.6938\n",
      "Epoch [8/10] Batch 800/938                   Loss D: 0.0193, loss G: 4.6778\n",
      "Epoch [8/10] Batch 900/938                   Loss D: 0.0198, loss G: 5.0583\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76c8da69bd94d43b1579ef5a2d15e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10:   0%|          | 0/938 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10] Batch 0/938                   Loss D: 0.3266, loss G: 2.0449\n",
      "Epoch [9/10] Batch 100/938                   Loss D: 0.1462, loss G: 3.2131\n",
      "Epoch [9/10] Batch 200/938                   Loss D: 0.2079, loss G: 2.8085\n",
      "Epoch [9/10] Batch 300/938                   Loss D: 0.1827, loss G: 4.0426\n",
      "Epoch [9/10] Batch 400/938                   Loss D: 0.1812, loss G: 3.0821\n",
      "Epoch [9/10] Batch 500/938                   Loss D: 0.0596, loss G: 4.1957\n",
      "Epoch [9/10] Batch 600/938                   Loss D: 0.0082, loss G: 5.5505\n",
      "Epoch [9/10] Batch 700/938                   Loss D: 0.0090, loss G: 5.3081\n",
      "Epoch [9/10] Batch 800/938                   Loss D: 0.0178, loss G: 5.1770\n",
      "Epoch [9/10] Batch 900/938                   Loss D: 0.0049, loss G: 6.4314\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "gen.train()\n",
    "disc.train()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for batch_idx, (real, _) in enumerate(tqdm(loader, desc=f'Epoch {epoch+1}', unit='batch')):\n",
    "        real = real.to(device)\n",
    "        noise = torch.randn(BATCH_SIZE, Z_DIM, 1, 1).to(device)\n",
    "\n",
    "\n",
    "        # Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
    "        disc_real = disc(real).reshape(-1)\n",
    "        lossD_real = criterion(disc_real, torch.ones_like(disc_real).to(device))\n",
    "        fake = gen(noise)\n",
    "        disc_fake = disc(fake).reshape(-1)\n",
    "        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake).to(device))\n",
    "        loss_disc = (lossD_real + lossD_fake) / 2\n",
    "\n",
    "        disc.zero_grad()\n",
    "\n",
    "        loss_disc.backward(retain_graph=True)\n",
    "\n",
    "        opt_disc.step()\n",
    "\n",
    "        #Train Generator\n",
    "        output = disc(fake).reshape(-1)\n",
    "        loss_gen = criterion(output, torch.ones_like(output).to(device))\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(dataloader)} \\\n",
    "                  Loss D: {loss_disc:.4f}, loss G: {loss_gen:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise)\n",
    "                # take out (up to) 32 examples\n",
    "                img_grid_real = torchvision.utils.make_grid(real[:32], normalize=True)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n",
    "\n",
    "                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
    "\n",
    "            step += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_real.close()\n",
    "writer_fake.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6014 (pid 38563), started 0:00:08 ago. (Use '!kill 38563' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a6f7351ced12e203\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a6f7351ced12e203\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6014;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
